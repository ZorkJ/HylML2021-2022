{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import ConcatDataset, Dataset, DataLoader, Subset\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm import tqdm\n",
    "\n",
    "_exp_name = \"sol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seed(seed):\n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "my_seed = 6666\n",
    "same_seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transforms**\n",
    "Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n",
    "\n",
    "Please refer to PyTorch official website for details about different transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform1 = transforms.RandomHorizontalFlip()\n",
    "transform2 = transforms.RandomRotation(30)\n",
    "transform3 = transforms.ColorJitter(brightness=0.5)\n",
    "transform4 = transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(0.7, 1.3))\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_transform = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    \n",
    "    # You may add some transforms here.\n",
    "    # transforms.RandomResizedCrop(size=(128, 128), antialias=True),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5), #50%的概率水平翻转\n",
    "    # transforms.RandomVerticalFlip(p=0.5), #50%的概率垂直翻转\n",
    "    # transforms.RandomRotation(degrees=(0, 180)),\n",
    "    # transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "    # transforms.RandomCrop(128, padding=10),\n",
    "    # transforms.RandomGrayscale(p=0.1),  #根据概率转灰度\n",
    "    \n",
    "    transforms.RandomChoice([transform1, transform2, transform3, transform4]), # 对每个样本随意挑选一种转换方式\n",
    "\n",
    "    # ToTensor() should be the last one of the transforms.\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datasets**\n",
    "The data is labelled by the name, so we load images and label while calling '__getitem__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import name\n",
    "\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, folder, transform = None, files = None):\n",
    "        super(FoodDataset, self).__init__()\n",
    "        self.path = folder\n",
    "        self.transform = transform\n",
    "        \n",
    "        if files is None:\n",
    "            self.files = sorted([os.path.join(folder, file) for file in os.listdir(folder) if file.endswith('.jpg')])\n",
    "        else:\n",
    "            self.files = files\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        image = Image.open(fname)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        name_split = fname.split('/')[-1].split('_')\n",
    "        if len(name_split) > 1:\n",
    "            label = int(name_split[0])\n",
    "        else:\n",
    "            label = -1 # Testing data\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "You are free to modify the model architecture here for further improvement. However, if you want to use some well-known architectures such as ResNet50, please make sure NOT to load the pre-trained weights. Using such pre-trained models is considered cheating and therefore you will be punished. Similarly, it is your responsibility to make sure no pre-trained weights are used if you use torch.hub to load any modules.\n",
    "\n",
    "For example, if you use ResNet-18 as your model:\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False) → This is fine.\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True) → This is NOT allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FoodClassifier, self).__init__()\n",
    "        # Define your neural network here\n",
    "        \n",
    "        # input image size: [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1), # [64, 128, 128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0), # [64, 64, 64]\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0), # [128, 32, 32]\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0), # [256, 16, 16]\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0), # [512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0), # [512, 4, 4]\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.flatten(1)\n",
    "        return self.fc(out)\n",
    "    \n",
    "    \n",
    "def params_count(model):\n",
    "    \"\"\"\n",
    "    Compute the number of parameters.\n",
    "    Args:\n",
    "        model (model): model to count the number of parameters.\n",
    "    \"\"\"\n",
    "    # return np.sum([p.numel() for p in model.parameters()]).item()\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "_dataset_dir = \"../input/ml2022spring-hw3b/food11\"\n",
    "\n",
    "# 也可以用DatasetFolder來讀取資料\n",
    "# filename 是图片的category, 不适用于2022年的作业, 所以还是用dataset自己的方法\n",
    "# train_dataset = DatasetFolder(_dataset_dir + '/training', loader=lambda x: Image.open(x), extensions='jpg', transform=train_transform)\n",
    "# valid_dataset = DatasetFolder(_dataset_dir + '/validation', loader=lambda x: Image.open(x), extensions='jpg', transform=test_transform)\n",
    "# test_dataset = DatasetFolder(_dataset_dir + '/testing', loader=lambda x: Image.open(x), extensions='jpg', transform=test_transform)\n",
    "# unlabeled_dataset = DatasetFolder(_dataset_dir + '/unlabeled', loader=lambda x: Image.open(x), extensions='jpg', transform=train_transform)\n",
    "\n",
    "train_dataset = FoodDataset(_dataset_dir + '/training', transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = FoodDataset(_dataset_dir + '/validation', transform=test_transform)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 如果使用KFold Cross Validation\n",
    "\n",
    "# 首先吧所有的数据集合并\n",
    "# all_dataset = ConcatDataset([train_dataset, valid_dataset])\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=my_seed)\n",
    "# k = 4\n",
    "# kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "# for fold, (train_idx, valid_idx) in enumerate(kf.split(all_dataset)):\n",
    "#     train_set = Subset(all_dataset, train_idx)\n",
    "#     valid_set = Subset(all_dataset, valid_idx)\n",
    "\n",
    "#     # Create data loaders for training and validation sets\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "#     valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# The number of training epochs and patience.\n",
    "n_epochs = 80\n",
    "patience = 300 # If no improvement in 'patience' epochs, early stop\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = FoodClassifier().to(device)\n",
    "\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
    "\n",
    "# Initialize trackers, these are not parameters and should not be changed\n",
    "stale = 0\n",
    "best_acc = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can finish supervised learning by simply running the provided code without any modification.\n",
    "\n",
    "The function \"get_pseudo_labels\" is used for semi-supervised learning.\n",
    "It is expected to get better performance if you use unlabeled data for semi-supervised learning.\n",
    "However, you have to implement the function on your own and need to adjust several hyperparameters manually.\n",
    "\n",
    "For more details about semi-supervised learning, please refer to [Prof. Lee's slides](https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/semi%20(v3).pdf).\n",
    "\n",
    "Again, please notice that utilizing external data (or pre-trained model) for training is **prohibited**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        return self.x[id][0], self.y[id] # self.x[id][0] is the image, self.y[id] is the label, self.x[id][1] is the original label\n",
    "\n",
    "def get_pseudo_labels(dataset, model, threshold=0.65):\n",
    "    # This functions generates pseudo-labels of a dataset using given model.\n",
    "    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n",
    "    # You are NOT allowed to use any models trained on external data for pseudo-labeling.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Construct a data loader.\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Make sure the model is in eval mode.\n",
    "    model.eval()\n",
    "    # Define softmax function.\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    idx = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over the dataset by batches.\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        img, _ = batch\n",
    "\n",
    "        # Forward the data\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(img.to(device))\n",
    "\n",
    "        # Obtain the probability distributions by applying softmax on logits.\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        # ---------- TODO ----------\n",
    "        # Filter the data and construct a new dataset.\n",
    "        for j, x in enumerate(probs):\n",
    "            if torch.max(x) > threshold:\n",
    "                idx.append(i * batch_size + j)\n",
    "                labels.append(int(torch.argmax(x)))\n",
    "\n",
    "    # # Turn off the eval mode.\n",
    "    model.train()\n",
    "    \n",
    "    print (\"\\nNew data: {:5d}\\n\".format(len(idx)))\n",
    "    dataset = PseudoDataset(Subset(dataset, idx), labels)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Whether to do semi-supervised learning.\n",
    "do_semi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # ---------- Training ----------\n",
    "    # In each epoch, relabel the unlabeled dataset for semi-supervised learning.\n",
    "    # Then you can combine the labeled dataset and pseudo-labeled dataset for the training.\n",
    "    if do_semi:\n",
    "        # Obtain pseudo-labels for unlabeled data using trained model.\n",
    "        pseudo_dataset = get_pseudo_labels(unlabeled_set, model)\n",
    "\n",
    "        # Construct a new dataset and a data loader for training.\n",
    "        # This is used in semi-supervised learning only.\n",
    "        concat_dataset = ConcatDataset([train_dataset, pseudo_dataset])\n",
    "        train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "        \n",
    "        \n",
    "    # Make sure the model is in train mode before training.\n",
    "    model.train()\n",
    "    \n",
    "    # These are used to record information in training.\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    \n",
    "    # Iterate the training set by batches.\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward the data\n",
    "        logits = model(imgs)\n",
    "        # Calculate the cross-entropy loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the gradients for parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip the gradient norms for stable training.\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        \n",
    "        # Update the parameters with computed gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "        \n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    \n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "    model.eval()\n",
    "    \n",
    "    # These are used to record information in validation.\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(valid_loader):\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        # We don't need gradient in validation.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs)\n",
    "        \n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        # Record the loss and accuracy.\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "        \n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    \n",
    "    # Print the information.\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    \n",
    "    # update logs\n",
    "    if valid_acc > best_acc:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
    "    else:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    \n",
    "    # ---------- Early Stopping ----------\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        stale = 0\n",
    "        torch.save(model.state_dict(), f\"{_exp_name}.pth\")\n",
    "    else:\n",
    "        stale += 1\n",
    "        if stale >= patience:\n",
    "            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and generate prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), transform=test_transform)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "model_best = FoodClassifier().to(device)\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}.pth\"))\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        prediction += test_label.squeeze().tolist()\n",
    "        \n",
    "        \n",
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
