{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Define some useful functions\n",
    "\n",
    "\n",
    "import test\n",
    "\n",
    "\n",
    "def same_seed(seed):\n",
    "    \"\"\"Fixed random seed to make results reproducible\"\"\"\n",
    "    \n",
    "    # 设置cudnn后端为确定性模式, 这可以保证每次运行网络的时候，相同输入的输出是确定的\n",
    "    # 但是这样会影响性能，因为cudnn的确定性模式会禁用一些优化算法\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # 关闭cudnn的benchmark模式, benchmark模式会自动寻找最适合当前配置的高效算法\n",
    "    # 这样会导致每次运行的时候，相同输入的输出不一定是相同的\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # 设置numpy的随机种子\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 设置Pytorch的全局随机种子, 会影响模型从初始化、随机丢弃层等操作的随机性\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # 检查是否有GPU可用, 如果有GPU的话，则设置cuda的随机种子\n",
    "    # 这段代码是深度学习实验中的最佳实践之一，特别是在需要复现结果或进行对比实验时非常重要。\n",
    "    # 需要注意的是，即使设置了这些种子，在多 GPU 环境下可能还需要额外的设置才能完全保证结果的可重复性, 如下面的代码所示\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "        \n",
    "def train_valid_split(dataset, val_size=0.2, batch_size=32, seed=2021):\n",
    "    \"\"\"Split a dataset into a training dataset and a validation dataset\"\"\"\n",
    "    \n",
    "    # 为保证每次运行的结果一致，设置随机种子\n",
    "    same_seed(seed)\n",
    "    \n",
    "    # 计算验证集的数量\n",
    "    val_length = int(len(dataset) * val_size)\n",
    "    \n",
    "    # 计算训练集的数量\n",
    "    train_length = len(dataset) - val_length\n",
    "    \n",
    "    # 使用torch.utils.data.random_split进行划分\n",
    "    train_dataset, valid_dataset = random_split(dataset, [train_length, val_length], \n",
    "                                                generator=torch.Generator().manual_seed(seed))\n",
    "    \n",
    "    return np.array(train_dataset), np.array(valid_dataset)\n",
    "\n",
    "\n",
    "def predict(test_loader, model, device):\n",
    "    \"\"\"Predict the output of a test dataset using a trained model\"\"\"\n",
    "    \n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    test_pred = []\n",
    "    for x in tqdm.tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            output = model(x)\n",
    "            test_pred.extend(output.detach().cpu().reshape(-1, 1))\n",
    "    print(test_pred)\n",
    "    preds = torch.cat(test_pred, dim=0).numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    \"\"\"COVID-19 X-ray image dataset\n",
    "    x: Features\n",
    "    y: Targets, if None, then return x only\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y = None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)\n",
    "            \n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.y is None:\n",
    "            return self.x[index]\n",
    "        else:\n",
    "            return self.x[index], self.y[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(train_data, valid_data, test_data, select_all = True):\n",
    "    y_train, y_valid = train_data[:, -1], valid_data[:, -1]\n",
    "    x_train, x_valid, x_test = train_data[:, :-1], valid_data[:, :-1], test_data\n",
    "    \n",
    "    if select_all:\n",
    "        feature_index = list(range(x_train.shape[1]))\n",
    "    else:\n",
    "        feature_index = [0, 1, 2, 3, 4] # can modify this line to select different features\n",
    "        \n",
    "    return x_train[:, feature_index], x_valid[:, feature_index], x_test[:, feature_index], y_train, y_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Traning and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    # reduction = 'mean' means that the sum of the squared errors will be divided by the number of samples\n",
    "    criterion = nn.MSELoss(reduction = 'mean') \n",
    "    \n",
    "    # Define optimizer\n",
    "    # optimizer = optim.Adam(model.parameters(), lr = config['learning_rate'])\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config['learning_rate'], momentum=0.9)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir = config['log_dir'])\n",
    "    \n",
    "    model_dir = config['model_dir']\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set the model to training mode\n",
    "        \n",
    "        loss_record = []\n",
    "        \n",
    "        # tqdm is a library that can display the progress bar\n",
    "        # position = 0 means the progress bar will be displayed at the first line\n",
    "        # leave = True means the progress bar will leave after finishing\n",
    "        train_pbar = tqdm.tqdm(train_loader, position = 0, leave = True)\n",
    "        \n",
    "        for x, y in train_pbar:\n",
    "            x, y = x.to(device), y.to(device) # Move your data to device.\n",
    "            \n",
    "            optimizer.zero_grad() # Set gradient to zero.\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()  # Compute gradient(backpropagation).\n",
    "            optimizer.step() # Update parameters.\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "            # detach the loss to convert it to a scalar\n",
    "            loss_record.append(loss.detach().item())\n",
    "        \n",
    "        mean_train_loss = sum(loss_record) / len(loss_record)\n",
    "        writer.add_scalar('train_loss', mean_train_loss, epoch)\n",
    "        \n",
    "        # switch to evaluation mode\n",
    "        model.eval()\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "                loss_record.append(loss.item())\n",
    "                \n",
    "        mean_valid_loss = sum(loss_record) / len(loss_record)\n",
    "        print(f\"EPOCH: {epoch}/{n_epochs}, TRAIN LOSS: {mean_train_loss:.4f}, VALID LOSS: {mean_valid_loss:.4f}\")\n",
    "        writer.add_scalar('valid_loss', mean_valid_loss, epoch)\n",
    "        \n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path'])\n",
    "            print(\"Saving model with valid loss: {best_loss:.4f}\")\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            \n",
    "        if early_stop_count > config['early_stop']:\n",
    "            print(\"\\nModel is not improving, so we halt the training session.\")\n",
    "            return \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from logging import config\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = {\n",
    "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': True,   # Whether to use all features.\n",
    "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 3000,     # Number of epochs.\n",
    "    'batch_size': 256,\n",
    "    'learning_rate': 1e-5,\n",
    "    'early_stop': 400,    # If model has not improved for this many consecutive epochs, stop training.\n",
    "    \"model_dir\": \"./models\",  # Your model will be saved here.\n",
    "    'save_path': './models/model.ckpt',  # Your best model save path\n",
    "    \"log_dir\": \"./logs\"  # Your tensorboard log path\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "Read data from files and set up training, validation, and testing sets. You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_seed(config['seed'])\n",
    "\n",
    "train_data = pd.read_csv('../Data/covid.train.csv').values\n",
    "test_data = pd.read_csv('../Data/covid.test.csv').values\n",
    "\n",
    "train_data, valid_data = train_valid_split(train_data, val_size=config['valid_ratio'], seed=config['seed'])\n",
    "\n",
    "# print out the data size\n",
    "print(f\"\"\"train_data size: {train_data.shape}\n",
    "valid_data size: {valid_data.shape}\n",
    "test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "# select features\n",
    "x_train, x_valid, x_test, y_train, y_valid = select_features(train_data, valid_data, test_data, config['select_all'])\n",
    "\n",
    "# Print out the number of features.\n",
    "print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "train_dataset = COVID19Dataset(x_train, y_train)\n",
    "valid_dataset = COVID19Dataset(x_valid, y_valid)\n",
    "test_dataset = COVID19Dataset(x_test)\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "# shuffle=True means the data will be shuffled.\n",
    "# pin_memory=True means the data will be loaded to GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = My_Model(x_train.shape[1]).to(device) # Move model to device.\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot learning curves with `tensorboard` (optional)\n",
    "\n",
    "`tensorboard` is a tool that allows you to visualize your training progress.\n",
    "\n",
    "If this block does not display your learning curve, please wait for few minutes, and re-run this block. It might take some time to load your logging information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    \n",
    "    preds_df = pd.DataFrame(preds, columns=['tested_positive'])\n",
    "    preds_df.index.name = 'id'\n",
    "    preds_df.to_csv(file)\n",
    "    \n",
    "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device)\n",
    "save_pred(preds, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
